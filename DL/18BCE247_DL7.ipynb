{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "18BCE247_DL7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOhmHI8hry7g8X6jw/JpA5A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/urvashiramdasani/ML-DL-Python/blob/master/DL/18BCE247_DL7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62ZOvYXjExVR"
      },
      "source": [
        "Name : Urvashi Ramdasani\n",
        "\n",
        "Division : EL3\n",
        "\n",
        "Aim : Build a language model using RNN. Write functions to sample novel sentences and find the probability of input sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoQ8mkSdEt8s"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, SimpleRNN, Embedding\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY8E6ztNHkED",
        "outputId": "e51ee335-cf05-440e-802e-64194454be5e"
      },
      "source": [
        "data = \"\"\" Jack and Jill went up the hill .\\n To fetch a pail of water .\\n Jack fell down and broke his crown .\\n And Jill came tumbling after .\"\"\".split(\"\\n\")\n",
        "print(data, type(data))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' Jack and Jill went up the hill .', ' To fetch a pail of water .', ' Jack fell down and broke his crown .', ' And Jill came tumbling after .'] <class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dwI2AaLI5jR"
      },
      "source": [
        "tokenizer = Tokenizer(filters = '!\"#$%&()*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n') # all special characters except period"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0BJLjHQQOiP",
        "outputId": "954e2db7-495b-472c-a3b8-5a3bb6970917"
      },
      "source": [
        "tokenizer.fit_on_texts(data)\n",
        "vocabulary = tokenizer.word_index\n",
        "print('Word Indices : ', vocabulary)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word Indices :  {'.': 1, 'and': 2, 'jack': 3, 'jill': 4, 'went': 5, 'up': 6, 'the': 7, 'hill': 8, 'to': 9, 'fetch': 10, 'a': 11, 'pail': 12, 'of': 13, 'water': 14, 'fell': 15, 'down': 16, 'broke': 17, 'his': 18, 'crown': 19, 'came': 20, 'tumbling': 21, 'after': 22}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfTDrKKdQXH2",
        "outputId": "1f733cfd-fcf7-4a5c-d376-300fa507dfe2"
      },
      "source": [
        "vocab_size = len(vocabulary) + 1\n",
        "print('Vocabulary Size: ', vocab_size)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size:  23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU4Z8hH7lwrA",
        "outputId": "78c75ac2-f1e8-4f9b-aee2-db82e72cd377"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(data)\n",
        "print(sequences)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3, 2, 4, 5, 6, 7, 8, 1], [9, 10, 11, 12, 13, 14, 1], [3, 15, 16, 2, 17, 18, 19, 1], [2, 4, 20, 21, 22, 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcgVWPjc5FPD",
        "outputId": "f5dce60a-9bc7-4611-d1d8-02fa5b27d44c"
      },
      "source": [
        "# Generating lists with and without period\n",
        "\n",
        "x = list()\n",
        "y = list()\n",
        "\n",
        "for i in range(len(sequences)):\n",
        "  x.insert(i, sequences[i][:-1])\n",
        "  y.insert(i, sequences[i])\n",
        "\n",
        "print('List x = ', x)\n",
        "print('List y = ', y)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "List x =  [[3, 2, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14], [3, 15, 16, 2, 17, 18, 19], [2, 4, 20, 21, 22]]\n",
            "List y =  [[3, 2, 4, 5, 6, 7, 8, 1], [9, 10, 11, 12, 13, 14, 1], [3, 15, 16, 2, 17, 18, 19, 1], [2, 4, 20, 21, 22, 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYD4k30PTNw8",
        "outputId": "5fdb8481-6981-4fad-d647-e52daa232d87"
      },
      "source": [
        "max_len = max([len(sequence) for sequence in x])\n",
        "print('Maximum length sequence : ', max_len)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum length sequence :  7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTM_l9rXmj2w",
        "outputId": "e23a1444-d564-4bfe-ad71-b93e158cf56f"
      },
      "source": [
        "x_padded = pad_sequences(x, maxlen = max_len, padding = 'pre')\n",
        "print(x_padded)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 3  2  4  5  6  7  8]\n",
            " [ 0  9 10 11 12 13 14]\n",
            " [ 3 15 16  2 17 18 19]\n",
            " [ 0  0  2  4 20 21 22]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSiwNm8uYfjG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94ed85ab-8005-4546-f270-f996da9e67d1"
      },
      "source": [
        "y_padded = pad_sequences(y, maxlen = max_len, padding = 'post')\n",
        "print(y_padded)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2  4  5  6  7  8  1]\n",
            " [ 9 10 11 12 13 14  1]\n",
            " [15 16  2 17 18 19  1]\n",
            " [ 2  4 20 21 22  1  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOuO4CSnZU7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "507b63ec-6c48-4c7b-ea81-2d7105aeccf2"
      },
      "source": [
        "y_padded = to_categorical(y_padded, num_classes = vocab_size)\n",
        "print(y_padded)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLfOasAgmXd3",
        "outputId": "7e41fd9c-03fd-4d53-f343-7f2038e18b8e"
      },
      "source": [
        "# Define the model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim = vocab_size, output_dim = 10))\n",
        "model.add(SimpleRNN(units = 50, return_sequences = True))\n",
        "model.add(Dense(units = vocab_size, activation = 'softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 10)          230       \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, None, 50)          3050      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, None, 23)          1173      \n",
            "=================================================================\n",
            "Total params: 4,453\n",
            "Trainable params: 4,453\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41F2yKPWmdM-"
      },
      "source": [
        "# Compile the model\n",
        "\n",
        "model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9A5d2FbnAb-",
        "outputId": "1861b8e2-6a7f-4d70-d56c-7d7b746372aa"
      },
      "source": [
        "# Fit the model\n",
        "\n",
        "model.fit(x_padded, y_padded, epochs = 100)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.1274 - accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.0968 - accuracy: 0.1429\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.0687 - accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.0362 - accuracy: 0.1786\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.9964 - accuracy: 0.1429\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.9483 - accuracy: 0.1429\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.8948 - accuracy: 0.1429\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8429 - accuracy: 0.1429\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7996 - accuracy: 0.1429\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.7653 - accuracy: 0.1429\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7364 - accuracy: 0.1429\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7099 - accuracy: 0.1429\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6842 - accuracy: 0.1429\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6584 - accuracy: 0.1429\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6319 - accuracy: 0.1429\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6044 - accuracy: 0.1786\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5758 - accuracy: 0.2143\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5459 - accuracy: 0.2143\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.5150 - accuracy: 0.2143\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4833 - accuracy: 0.2857\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4511 - accuracy: 0.3214\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4188 - accuracy: 0.3571\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3867 - accuracy: 0.3571\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3550 - accuracy: 0.4286\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3239 - accuracy: 0.4643\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2934 - accuracy: 0.4643\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2635 - accuracy: 0.5000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2343 - accuracy: 0.5000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2055 - accuracy: 0.5000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1772 - accuracy: 0.5000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1493 - accuracy: 0.5000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1217 - accuracy: 0.5357\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0944 - accuracy: 0.5357\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0673 - accuracy: 0.5714\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0404 - accuracy: 0.6071\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0137 - accuracy: 0.6071\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.9872 - accuracy: 0.6071\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.9608 - accuracy: 0.6071\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.9345 - accuracy: 0.6071\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.9083 - accuracy: 0.6786\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8823 - accuracy: 0.6786\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.8563 - accuracy: 0.6786\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8304 - accuracy: 0.7143\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.8047 - accuracy: 0.7143\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7790 - accuracy: 0.7143\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7535 - accuracy: 0.7143\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7281 - accuracy: 0.7857\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.7029 - accuracy: 0.7857\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6778 - accuracy: 0.7857\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6528 - accuracy: 0.7857\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6280 - accuracy: 0.7857\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.6034 - accuracy: 0.7857\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5789 - accuracy: 0.8214\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5547 - accuracy: 0.8571\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5306 - accuracy: 0.8571\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5067 - accuracy: 0.8571\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4831 - accuracy: 0.8571\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4598 - accuracy: 0.8571\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4371 - accuracy: 0.8571\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4149 - accuracy: 0.8571\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3931 - accuracy: 0.8571\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3705 - accuracy: 0.8571\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.3485 - accuracy: 0.8571\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3266 - accuracy: 0.8571\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.3051 - accuracy: 0.8571\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2839 - accuracy: 0.8571\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2630 - accuracy: 0.8929\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2423 - accuracy: 0.8929\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2218 - accuracy: 0.8929\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2016 - accuracy: 0.8929\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1816 - accuracy: 0.8929\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1617 - accuracy: 0.8929\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1422 - accuracy: 0.8929\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1228 - accuracy: 0.8929\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1037 - accuracy: 0.8929\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0848 - accuracy: 0.8929\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0661 - accuracy: 0.8929\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0477 - accuracy: 0.8929\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0296 - accuracy: 0.8929\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0117 - accuracy: 0.8929\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9940 - accuracy: 0.8929\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9767 - accuracy: 0.9286\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9596 - accuracy: 0.9286\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9427 - accuracy: 0.9286\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9262 - accuracy: 0.9286\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.9099 - accuracy: 0.9286\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8938 - accuracy: 0.9286\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8781 - accuracy: 0.9286\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8626 - accuracy: 0.9286\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8474 - accuracy: 0.9286\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8325 - accuracy: 0.9286\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8179 - accuracy: 0.9286\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8035 - accuracy: 0.9286\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7893 - accuracy: 0.9286\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7754 - accuracy: 0.9286\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7617 - accuracy: 0.9286\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7483 - accuracy: 0.9286\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7350 - accuracy: 0.9286\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7221 - accuracy: 0.9286\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7093 - accuracy: 0.9286\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f07d4078750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1DfSiqQnJL4"
      },
      "source": [
        "def prob_input_sentence(model, tokenizer, sentence):\n",
        "  encoded = tokenizer.texts_to_sequences([sentence])[0]\n",
        "  encoded.insert(0, 0)\n",
        "  encoded = np.array(encoded)\n",
        "  encoded = np.reshape(encoded, newshape = (1, -1))\n",
        "  prob = model.predict_proba(encoded, verbose = 0)\n",
        "  probability = 1\n",
        "  for i in range(prob.shape[1] - 1):\n",
        "    probability *= prob[0, i, encoded[0, i + 1]]\n",
        "  print('The probability of sentence ', sentence, ' is ', probability)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcQZ60EKoaR2",
        "outputId": "89241960-4768-43f7-e344-1f656e84b768"
      },
      "source": [
        "prob_input_sentence(model, tokenizer, 'Jack and Jill went up')\n",
        "prob_input_sentence(model, tokenizer, 'and Jill went up')\n",
        "prob_input_sentence(model, tokenizer, 'went up the hill')\n",
        "prob_input_sentence(model, tokenizer, 'Jack and Jill went up the hill')\n",
        "prob_input_sentence(model, tokenizer, 'to fetch a pail')\n",
        "prob_input_sentence(model, tokenizer, 'fetch a pail')\n",
        "prob_input_sentence(model, tokenizer, 'to fetch a pail of water')\n",
        "prob_input_sentence(model, tokenizer, 'Jack fell down and')\n",
        "prob_input_sentence(model, tokenizer, 'Jack fell down and broke')\n",
        "prob_input_sentence(model, tokenizer, 'fell down and broke')\n",
        "prob_input_sentence(model, tokenizer, 'Jack fell down and broke his crown')\n",
        "prob_input_sentence(model, tokenizer, 'and Jill came tumbling')\n",
        "prob_input_sentence(model, tokenizer, 'Jill came tumbling after')\n",
        "prob_input_sentence(model, tokenizer, 'and Jill came tumbling after')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The probability of sentence  Jack and Jill went up  is  4.046618947431747e-08\n",
            "WARNING:tensorflow:5 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f07cff9d200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "The probability of sentence  and Jill went up  is  0.0006520378597691507\n",
            "The probability of sentence  went up the hill  is  1.302733400251648e-05\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f07cff9d200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "The probability of sentence  Jack and Jill went up the hill  is  2.0313087823372113e-10\n",
            "The probability of sentence  to fetch a pail  is  0.014515784069070246\n",
            "The probability of sentence  fetch a pail  is  2.0629078529688497e-06\n",
            "The probability of sentence  to fetch a pail of water  is  0.009894810556752778\n",
            "The probability of sentence  Jack fell down and  is  2.299133628315368e-06\n",
            "The probability of sentence  Jack fell down and broke  is  1.3553367788220498e-07\n",
            "The probability of sentence  fell down and broke  is  0.0001451889069790434\n",
            "The probability of sentence  Jack fell down and broke his crown  is  6.122907999162922e-09\n",
            "The probability of sentence  and Jill came tumbling  is  0.0020658467480818045\n",
            "The probability of sentence  Jill came tumbling after  is  2.722586856795852e-06\n",
            "The probability of sentence  and Jill came tumbling after  is  0.0005223050754797519\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJw-ZtHbqm63"
      },
      "source": [
        "## Word Level Language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iK08L2KTqpAw"
      },
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, SimpleRNN, Embedding\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B3emXqir9IG",
        "outputId": "f83730ab-0ed3-45e4-f00e-a603f4cf4f2a"
      },
      "source": [
        "data = \"\"\" Jack and Jill went up the hill .\\n To fetch a pail of water .\\n Jack fell down and broke his crown .\\n And Jill came tumbling after .\"\"\".split('\\n')\n",
        "print(data, type(data))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' Jack and Jill went up the hill .', ' To fetch a pail of water .', ' Jack fell down and broke his crown .', ' And Jill came tumbling after .'] <class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT6O6a-sthON"
      },
      "source": [
        "tokenizer = Tokenizer(filters = '!\"#$%&()*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXVFcaMHuRK5",
        "outputId": "b9c87412-0b69-4959-daa4-28109de9f4cf"
      },
      "source": [
        "tokenizer.fit_on_texts(data)\n",
        "vocabulary = tokenizer.word_index\n",
        "print('Word Indices : ', vocabulary)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word Indices :  {'.': 1, 'and': 2, 'jack': 3, 'jill': 4, 'went': 5, 'up': 6, 'the': 7, 'hill': 8, 'to': 9, 'fetch': 10, 'a': 11, 'pail': 12, 'of': 13, 'water': 14, 'fell': 15, 'down': 16, 'broke': 17, 'his': 18, 'crown': 19, 'came': 20, 'tumbling': 21, 'after': 22}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwjSdHwouSDa",
        "outputId": "7084be71-4421-4245-b6dd-713df9d570b2"
      },
      "source": [
        "vocab_size = len(vocabulary) + 1\n",
        "print('Vocabulary Size: ', vocab_size)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size:  23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlpngpX-zS3k",
        "outputId": "1b7607fa-8950-4049-9ff4-2e0638df5eaa"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(data)\n",
        "print(sequences)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3, 2, 4, 5, 6, 7, 8, 1], [9, 10, 11, 12, 13, 14, 1], [3, 15, 16, 2, 17, 18, 19, 1], [2, 4, 20, 21, 22, 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E79JxUXhuWSg",
        "outputId": "24d2d33e-4f3f-4596-dc89-6432b6c0985e"
      },
      "source": [
        "# Generating lists with and without period\n",
        "\n",
        "x = list()\n",
        "y = list()\n",
        "\n",
        "for i in range(len(sequences)):\n",
        "  x.insert(i, sequences[i][:-1])\n",
        "  y.insert(i, sequences[i])\n",
        "\n",
        "print('List x = ', x)\n",
        "print('List y = ', y)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "List x =  [[3, 2, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14], [3, 15, 16, 2, 17, 18, 19], [2, 4, 20, 21, 22]]\n",
            "List y =  [[3, 2, 4, 5, 6, 7, 8, 1], [9, 10, 11, 12, 13, 14, 1], [3, 15, 16, 2, 17, 18, 19, 1], [2, 4, 20, 21, 22, 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJj_BmhgzeQN",
        "outputId": "9cde56e6-66a0-4dde-9668-f8ff81b5bbb2"
      },
      "source": [
        "max_len = max([len(sequence) for sequence in x])\n",
        "print('Maximum length sequence : ', max_len)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum length sequence :  7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uy4X23Z9zn1k",
        "outputId": "3f03d5b4-5a06-41a5-a7ba-a123d91564de"
      },
      "source": [
        "x_padded = pad_sequences(x, maxlen = max_len, padding = 'pre')\n",
        "print(x_padded)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 3  2  4  5  6  7  8]\n",
            " [ 0  9 10 11 12 13 14]\n",
            " [ 3 15 16  2 17 18 19]\n",
            " [ 0  0  2  4 20 21 22]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BjkmFke0mIO",
        "outputId": "37b31d0a-f211-4427-b92c-5a091e1972b9"
      },
      "source": [
        "y_padded = pad_sequences(y, maxlen = max_len, padding = 'post')\n",
        "print(y_padded)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2  4  5  6  7  8  1]\n",
            " [ 9 10 11 12 13 14  1]\n",
            " [15 16  2 17 18 19  1]\n",
            " [ 2  4 20 21 22  1  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0qe8dC7z08p",
        "outputId": "396b3526-bd19-4d6d-8a8a-c5d99bd8d537"
      },
      "source": [
        "y_padded = to_categorical(y_padded, num_classes = vocab_size)\n",
        "print(y_padded)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoEAos6s0gWw",
        "outputId": "755d0cd6-1414-4751-f4f4-364f040604c3"
      },
      "source": [
        "# Define the model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim = vocab_size, output_dim = 10))\n",
        "model.add(SimpleRNN(units = 50, return_sequences = True))\n",
        "model.add(Dense(units = vocab_size, activation = 'softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 10)          230       \n",
            "_________________________________________________________________\n",
            "simple_rnn (SimpleRNN)       (None, None, 50)          3050      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, None, 23)          1173      \n",
            "=================================================================\n",
            "Total params: 4,453\n",
            "Trainable params: 4,453\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf_mEN1m3tpi"
      },
      "source": [
        "# Compile the model\n",
        "\n",
        "model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cd0lYf8C38ge",
        "outputId": "b819de84-8aed-4d4f-bacf-78acfe5e986e"
      },
      "source": [
        "# Fit the model\n",
        "\n",
        "model.fit(x_padded, y_padded, epochs = 100)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.1423 - accuracy: 0.0357\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1095 - accuracy: 0.1429\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.0799 - accuracy: 0.1429\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0452 - accuracy: 0.1429\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0021 - accuracy: 0.1429\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.9499 - accuracy: 0.1429\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8942 - accuracy: 0.1429\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8449 - accuracy: 0.1429\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8072 - accuracy: 0.1429\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7788 - accuracy: 0.1429\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7554 - accuracy: 0.1429\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7346 - accuracy: 0.1429\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7148 - accuracy: 0.1429\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6955 - accuracy: 0.1429\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6762 - accuracy: 0.1429\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6566 - accuracy: 0.1786\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6365 - accuracy: 0.2143\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6158 - accuracy: 0.2143\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5942 - accuracy: 0.2143\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5717 - accuracy: 0.2500\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5482 - accuracy: 0.2500\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5236 - accuracy: 0.2500\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4978 - accuracy: 0.2500\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4709 - accuracy: 0.2500\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4430 - accuracy: 0.2857\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4140 - accuracy: 0.3214\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3842 - accuracy: 0.3571\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3536 - accuracy: 0.4286\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3225 - accuracy: 0.4286\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2909 - accuracy: 0.4286\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2590 - accuracy: 0.4286\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2268 - accuracy: 0.4643\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1945 - accuracy: 0.5000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1620 - accuracy: 0.5357\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1295 - accuracy: 0.6071\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0969 - accuracy: 0.6071\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.0644 - accuracy: 0.6429\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.0319 - accuracy: 0.6786\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9996 - accuracy: 0.6786\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9674 - accuracy: 0.6786\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.9355 - accuracy: 0.6786\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9038 - accuracy: 0.6786\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8724 - accuracy: 0.6786\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8414 - accuracy: 0.6786\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8107 - accuracy: 0.7143\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7804 - accuracy: 0.7143\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7505 - accuracy: 0.7143\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.7210 - accuracy: 0.7143\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.6919 - accuracy: 0.7143\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6632 - accuracy: 0.7143\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6349 - accuracy: 0.7143\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6071 - accuracy: 0.7143\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5797 - accuracy: 0.7143\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.5527 - accuracy: 0.7143\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5261 - accuracy: 0.7500\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.4999 - accuracy: 0.7500\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4742 - accuracy: 0.7857\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4488 - accuracy: 0.7857\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4238 - accuracy: 0.7857\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3993 - accuracy: 0.7857\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3751 - accuracy: 0.7857\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.3513 - accuracy: 0.7857\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.3279 - accuracy: 0.8214\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.3049 - accuracy: 0.8214\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2822 - accuracy: 0.8214\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2600 - accuracy: 0.8214\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.2381 - accuracy: 0.8214\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2167 - accuracy: 0.8571\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1956 - accuracy: 0.8571\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1748 - accuracy: 0.8571\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.1545 - accuracy: 0.8571\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1344 - accuracy: 0.8571\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1148 - accuracy: 0.8571\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0955 - accuracy: 0.8571\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0765 - accuracy: 0.8571\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0579 - accuracy: 0.8571\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0396 - accuracy: 0.8571\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0216 - accuracy: 0.8571\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0040 - accuracy: 0.8571\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9866 - accuracy: 0.8571\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9696 - accuracy: 0.8571\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9528 - accuracy: 0.8571\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9364 - accuracy: 0.8571\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9202 - accuracy: 0.8571\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9044 - accuracy: 0.8571\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8888 - accuracy: 0.8571\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8735 - accuracy: 0.8571\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8585 - accuracy: 0.8571\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8437 - accuracy: 0.8571\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8292 - accuracy: 0.8571\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8149 - accuracy: 0.8571\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8010 - accuracy: 0.8571\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7872 - accuracy: 0.8571\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7738 - accuracy: 0.8571\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7605 - accuracy: 0.8571\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7476 - accuracy: 0.8571\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7348 - accuracy: 0.8571\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7223 - accuracy: 0.8571\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7100 - accuracy: 0.8571\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6979 - accuracy: 0.8571\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f07dbbd4590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckOexu9Q4OEh"
      },
      "source": [
        "def sample_seq_wo_seed(model, tokenizer, n_words, vocab_size):\n",
        "  encoded = []\n",
        "  in_text = ''\n",
        "  for i in range(n_words):\n",
        "    encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "    encoded.insert(0, 0)\n",
        "    encoded = np.array(encoded)\n",
        "    encoded = np.reshape(encoded, newshape = (1, -1))\n",
        "\n",
        "    if i == 0:\n",
        "      prob = model.predict_proba(encoded, verbose = 0)\n",
        "      yhat = 0\n",
        "\n",
        "      while yhat == 0:\n",
        "        yhat = np.random.choice(range(vocab_size), p = prob.ravel())\n",
        "      \n",
        "      yhat = [yhat]\n",
        "      yhat = np.array(yhat)\n",
        "      yhat = np.reshape(yhat, newshape = (1, -1))\n",
        "    \n",
        "    else:\n",
        "      yhat = np.append(yhat, 0)\n",
        "      yhat = np.reshape(yhat, newshape = (1, -1))\n",
        "\n",
        "      while yhat[0, i] == 0:\n",
        "        yhat = model.predict_classes(encoded, verbose = 0)\n",
        "    \n",
        "    out_word = ''\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if index == yhat[0, i]:\n",
        "        out_word = word\n",
        "        break\n",
        "      \n",
        "    in_text = in_text + out_word + ' '\n",
        "  return in_text"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D-sJHDs2l7O",
        "outputId": "bb5cc825-88b6-4794-ffb9-a6c61533eb64"
      },
      "source": [
        "print(sample_seq_wo_seed(model, tokenizer, 8, vocab_size))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "to jill a pail of water . hill \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSz1io9w28tF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}